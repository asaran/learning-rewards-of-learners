{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to /tmp/openai-2019-05-11-17-42-09-557616\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import pickle\n",
    "import gym\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from run_test import *\n",
    "import atari_head_dataset as ahd \n",
    "import utils\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalize_state(obs):\n",
    "    obs = obs * 255.0\n",
    "    return obs.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env name:  breakout\n",
      "valid trials: ['218_RZ_7584753_Jan-15-14-40-41', '205_RZ_4137619_Dec-06-17-09-10', '198_RZ_3877709_Dec-03-16-56-11']\n",
      "valid trial nums: [218, 205, 198]\n",
      "1\n",
      "205 [218, 205, 198]\n",
      "randomly sampling a trial number for extra episodes in a trajectory\n",
      "1\n",
      "198 [218, 205, 198]\n",
      "randomly sampling a trial number for extra episodes in a trajectory\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    env_name = \"breakout\"\n",
    "    data_dir = \"../data/atari-head/\"\n",
    "    dataset = ahd.AtariHeadDataset(env_name, data_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13702\n",
      "traj length:  5\n",
      "Max human score 554\n",
      "Min human score 2\n",
      "num non duplicate scores 5\n",
      "len demos:  5\n",
      "89 89 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akanksha/learning-rewards-of-learners/learner/utils.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return obs/float(max_val)\n"
     ]
    }
   ],
   "source": [
    "    print(len(dataset.trajectories['breakout'][218]))\n",
    "    demonstrations, learning_returns, learning_rewards, learning_gaze = utils.get_preprocessed_trajectories(env_name, dataset, data_dir, use_gaze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n",
      "[[[0.         0.         0.         0.         1.         0.\n",
      "   0.        ]\n",
      "  [0.         0.         0.         0.         0.11023622 0.\n",
      "   0.        ]\n",
      "  [0.         0.         0.         0.         0.08661417 0.\n",
      "   0.        ]\n",
      "  [0.         0.         0.         0.         0.14173228 0.\n",
      "   0.        ]\n",
      "  [0.         0.4488189  0.1023622  0.12598425 0.99212598 0.\n",
      "   0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.        ]]]\n",
      "(1, 84, 84, 4)\n",
      "(1, 7, 7)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "    print(len(learning_gaze))\n",
    "    print(len(demonstrations))\n",
    "    #print(learning_rewards)\n",
    "    print((learning_gaze[0][0])) # gaze for first frame of first trajectory\n",
    "    print(demonstrations[0][0].shape)\n",
    "    print(learning_gaze[0][0].shape)\n",
    "    print(type(learning_gaze[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 84, 4)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "    from PIL import Image\n",
    "    data = demonstrations[0][0].squeeze()\n",
    "    print(data.shape)\n",
    "    print(len(learning_gaze[0][0]))\n",
    "    data = data[:,:,2]\n",
    "    data = unnormalize_state(data)\n",
    "    img = Image.fromarray(data)\n",
    "    basewidth = 600\n",
    "    wpercent = (basewidth/float(img.size[0]))\n",
    "    hsize = int((float(img.size[1])*float(wpercent)))\n",
    "    img_big = img.resize((basewidth,hsize), Image.ANTIALIAS)\n",
    "    img_big.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # convert PIL image frame to opencv format\n",
    "    pil_image = img.convert('RGB') \n",
    "    open_cv_image = np.array(pil_image) \n",
    "    # Convert RGB to BGR \n",
    "    open_cv_image = open_cv_image[:, :, ::-1].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.007874015748032\n",
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    gaze_map = learning_gaze[0][0].squeeze()\n",
    "    plt.imshow(gaze_map, cmap='hot', interpolation='nearest')\n",
    "    #ax = sns.heatmap(gaze_map, linewidth=0.5, cmap=\"YlGnBu\")\n",
    "    plt.show()\n",
    "    print(sum(sum(learning_gaze[0][0].squeeze())))\n",
    "    print(np.amax(learning_gaze[0][0]))\n",
    "    print(np.amin(learning_gaze[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 84, 3) <class 'numpy.ndarray'> uint8\n",
      "(84, 84, 3) <class 'numpy.ndarray'> uint8\n"
     ]
    }
   ],
   "source": [
    "    # overlay heatmap on image frames\n",
    "    cmap = plt.get_cmap('jet')\n",
    "    gaze_map_big = cv2.resize(gaze_map, (84,84), interpolation=cv2.INTER_AREA)\n",
    "    rgba_img = cmap(gaze_map_big)\n",
    "    rgb_img = np.delete(rgba_img, 3, 2)\n",
    "    rgb_img = np.asarray(rgb_img, np.uint8)\n",
    "    print(rgb_img.shape, type(rgb_img), rgb_img.dtype)\n",
    "    print(open_cv_image.shape, type(open_cv_image), open_cv_image.dtype)\n",
    "    blend = cv2.addWeighted(rgb_img,0.8,open_cv_image,0.2,0)\n",
    "    cv2.imshow(\"heatmap\",blend)\n",
    "    cv2.waitKey(0)\n",
    "#     plt.show(rgb_img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # visualize output of 4th conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # overlay conv layer output on image frames"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
