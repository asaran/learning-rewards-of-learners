{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to /tmp/openai-2018-11-28-19-07-56-749495\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import gym\n",
    "import time\n",
    "import numpy as np \n",
    "import random\n",
    "import torch\n",
    "from run_test import *\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set up the code for running trajectories with pong\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsbrown/anaconda3/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#try it just for two trajectories\n",
    "\n",
    "env_id = \"Hopper-v2\"\n",
    "task_name = \"\"\n",
    "env_type = \"mujoco\"\n",
    "\n",
    "#env id, env type, num envs, and seed\n",
    "env = make_vec_env(env_id, env_type, 1, 0,\n",
    "                   wrapper_kwargs={\n",
    "                       'clip_rewards':False,\n",
    "                       'episode_life':False,\n",
    "                   })\n",
    "\n",
    "\n",
    "env = VecNormalize(env,ob=True,ret=False,eval=True)\n",
    " \n",
    "agent = PPO2Agent(env, env_type)\n",
    "#agent = RandomAgent(env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "#get size of state space for neural net input\n",
    "n = env.observation_space.shape[0]\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_state(obs):\n",
    "    obs_highs = env.observation_space.high\n",
    "    obs_lows = env.observation_space.low\n",
    "    print(obs_highs)\n",
    "    print(obs_lows)\n",
    "    return  2.0 * (obs - obs_lows) / (obs_highs - obs_lows) - 1.0\n",
    "    #return obs / obs_highs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Max and min are infinite and -infinite\n",
    "#can't normalize this way!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00020', '00040', '00060', '00080', '00100', '00120', '00140', '00160', '00180', '00200', '00220', '00240', '00260', '00280', '00300', '00320', '00340', '00360', '00380', '00400', '00420', '00440', '00460', '00480']\n"
     ]
    }
   ],
   "source": [
    "checkpoint_min = 20\n",
    "checkpoint_max = 480\n",
    "checkpoint_step = 20\n",
    "checkpoints = []\n",
    "for i in range(checkpoint_min, checkpoint_max + checkpoint_step, checkpoint_step):\n",
    "    if i < 100:\n",
    "        checkpoints.append('000' + str(i))\n",
    "    elif i < 1000:\n",
    "        checkpoints.append('00' + str(i))\n",
    "print(checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint: 00020, steps: 620, return: 645.2108759582043\n",
      "traj length 620\n",
      "demo length 0\n",
      "checkpoint: 00040, steps: 199, return: 168.67658001184464\n",
      "traj length 199\n",
      "demo length 1\n",
      "checkpoint: 00060, steps: 777, return: 801.8340438604355\n",
      "traj length 777\n",
      "demo length 2\n",
      "checkpoint: 00080, steps: 172, return: 199.99827980995178\n",
      "traj length 172\n",
      "demo length 3\n",
      "checkpoint: 00100, steps: 79, return: 106.78841018676758\n",
      "traj length 79\n",
      "demo length 4\n",
      "checkpoint: 00120, steps: 56, return: 89.60489749908447\n",
      "traj length 56\n",
      "demo length 5\n",
      "checkpoint: 00140, steps: 54, return: 91.52551531791687\n",
      "traj length 54\n",
      "demo length 6\n",
      "checkpoint: 00160, steps: 57, return: 100.79859435558319\n",
      "traj length 57\n",
      "demo length 7\n",
      "checkpoint: 00180, steps: 75, return: 142.2026106119156\n",
      "traj length 75\n",
      "demo length 8\n",
      "checkpoint: 00200, steps: 96, return: 191.19741237163544\n",
      "traj length 96\n",
      "demo length 9\n",
      "checkpoint: 00220, steps: 113, return: 218.26495671272278\n",
      "traj length 113\n",
      "demo length 10\n",
      "checkpoint: 00240, steps: 126, return: 233.56191754341125\n",
      "traj length 126\n",
      "demo length 11\n",
      "checkpoint: 00260, steps: 112, return: 201.16741406917572\n",
      "traj length 112\n",
      "demo length 12\n",
      "checkpoint: 00280, steps: 104, return: 190.62159609794617\n",
      "traj length 104\n",
      "demo length 13\n",
      "checkpoint: 00300, steps: 88, return: 168.3785561323166\n",
      "traj length 88\n",
      "demo length 14\n",
      "checkpoint: 00320, steps: 89, return: 171.8237270116806\n",
      "traj length 89\n",
      "demo length 15\n",
      "checkpoint: 00340, steps: 82, return: 148.871102809906\n",
      "traj length 82\n",
      "demo length 16\n",
      "checkpoint: 00360, steps: 75, return: 138.04380345344543\n",
      "traj length 75\n",
      "demo length 17\n",
      "checkpoint: 00380, steps: 73, return: 129.63690614700317\n",
      "traj length 73\n",
      "demo length 18\n",
      "checkpoint: 00400, steps: 77, return: 138.3592414855957\n",
      "traj length 77\n",
      "demo length 19\n",
      "checkpoint: 00420, steps: 80, return: 148.59537827968597\n",
      "traj length 80\n",
      "demo length 20\n",
      "checkpoint: 00440, steps: 71, return: 118.79765176773071\n",
      "traj length 71\n",
      "demo length 21\n",
      "checkpoint: 00460, steps: 76, return: 128.91973638534546\n",
      "traj length 76\n",
      "demo length 22\n",
      "checkpoint: 00480, steps: 72, return: 114.66172862052917\n",
      "traj length 72\n",
      "demo length 23\n",
      "[645.2108759582043, 168.67658001184464, 801.8340438604355, 199.99827980995178, 106.78841018676758, 89.60489749908447, 91.52551531791687, 100.79859435558319, 142.2026106119156, 191.19741237163544, 218.26495671272278, 233.56191754341125, 201.16741406917572, 190.62159609794617, 168.3785561323166, 171.8237270116806, 148.871102809906, 138.04380345344543, 129.63690614700317, 138.3592414855957, 148.59537827968597, 118.79765176773071, 128.91973638534546, 114.66172862052917]\n"
     ]
    }
   ],
   "source": [
    "demonstrations = []\n",
    "learning_returns = []\n",
    "for checkpoint in checkpoints:\n",
    "    \n",
    "    model_path = \"./models/\" + task_name + \"/checkpoints/\" + checkpoint\n",
    "    \n",
    "    agent.load(model_path)\n",
    "    episode_count = 1\n",
    "    for i in range(episode_count):\n",
    "        done = False\n",
    "        traj = []\n",
    "        r = 0\n",
    "        \n",
    "        ob = env.reset()\n",
    "        #traj.append(ob)\n",
    "        #print(ob.shape)\n",
    "        steps = 0\n",
    "        acc_reward = 0\n",
    "        while True:\n",
    "            action = agent.act(ob, r, done)\n",
    "            ob, r, done, _ = env.step(action)\n",
    "            #print(ob.shape)\n",
    "            traj.append(ob)\n",
    "            steps += 1\n",
    "            acc_reward += r[0]\n",
    "            if done:\n",
    "                print(\"checkpoint: {}, steps: {}, return: {}\".format(checkpoint, steps,acc_reward))\n",
    "                break\n",
    "        print(\"traj length\", len(traj))\n",
    "        print(\"demo length\", len(demonstrations))\n",
    "        demonstrations.append(traj)\n",
    "        learning_returns.append(acc_reward)\n",
    "    \n",
    "\n",
    "\n",
    "env.close()\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "print(learning_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the returns to see if they are roughly monotonically increasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(learning_returns)\n",
    "plt.xlabel(\"Demonstration\")\n",
    "plt.ylabel(\"Return\")\n",
    "plt.savefig(\"hopper.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(learning_returns))\n",
    "print(len(demonstrations))\n",
    "print([a[0] for a in zip(learning_returns, demonstrations)])\n",
    "#cheat and sort them to see if it helps learning\n",
    "sorted_demos = [x for _, x in sorted(zip(learning_returns,demonstrations), key=lambda pair: pair[0])]\n",
    "\n",
    "sorted_returns = sorted(learning_returns)\n",
    "print(learning_returns)\n",
    "plt.plot(sorted_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_demos = []\n",
    "train_returns = []\n",
    "valid_demos = []\n",
    "valid_returns = []\n",
    "\n",
    "for i,d in enumerate(sorted_demos):\n",
    "    print(i)\n",
    "    if i % 5 is not 4:\n",
    "        train_demos.append(d)\n",
    "        train_returns.append(sorted_returns[i])\n",
    "    else:\n",
    "        valid_demos.append(d)\n",
    "        valid_returns.append(sorted_returns[i])\n",
    "\n",
    "print(train_returns)\n",
    "print(valid_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want to build a neural network to predict the reward the learner is trying to optimize. The inputs are 84x84x4 grayscale images. I'm going to try and use the NIPS architecture from DeepMind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Assume that we are on a CUDA machine, then this should print a CUDA device:\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(n, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        \n",
    "        \n",
    "    def cum_return(self, traj):\n",
    "        '''calculate cumulative return of trajectory'''\n",
    "        sum_rewards = 0\n",
    "        for x in traj:\n",
    "            x = F.leaky_relu(self.fc1(x))\n",
    "            r = torch.sigmoid(self.fc2(x)) #clip reward?\n",
    "            sum_rewards += r\n",
    "        ##    y = self.scalar(torch.ones(1))\n",
    "        ##    sum_rewards += y\n",
    "        #print(sum_rewards)\n",
    "        return sum_rewards\n",
    "        \n",
    "            \n",
    "    \n",
    "    def forward(self, traj_i, traj_j):\n",
    "        '''compute cumulative return for each trajectory and return logits'''\n",
    "        #print([self.cum_return(traj_i), self.cum_return(traj_j)])\n",
    "        return torch.cat([self.cum_return(traj_i), self.cum_return(traj_j)])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train the network. I'm just going to do it one by one for now. Could adapt it for minibatches to get better gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_reward(reward_network, optimizer, trajectories, num_iter):\n",
    "    loss_criterion = nn.CrossEntropyLoss()\n",
    "    #print(training_data[0])\n",
    "    cum_loss = 0.0\n",
    "    for epoch in range(num_iter):\n",
    "        #pick two random trajectories, traj_i and traj_j and give classification label to later one\n",
    "        j = np.random.randint(len(trajectories)) \n",
    "        i = np.random.randint(len(trajectories))\n",
    "        while(i == j):\n",
    "            i = np.random.randint(len(trajectories))\n",
    "        #print(i,j)\n",
    "        #traj_i = np.array([[d[0]] for d in trajectories[i]])\n",
    "        #traj_j = np.array([[d[0]] for d in trajectories[j]])\n",
    "        traj_i = np.array(trajectories[i])\n",
    "        traj_j = np.array(trajectories[j])\n",
    "        #print(\"orig trajs\")\n",
    "        #print(traj_i)\n",
    "        #print(traj_j)\n",
    "        \n",
    "        if i > j:\n",
    "            labels = np.array([[0]])\n",
    "        else:\n",
    "            labels = np.array([[1]])\n",
    "            \n",
    "        traj_i = torch.from_numpy(traj_i).float().to(device)\n",
    "        traj_j = torch.from_numpy(traj_j).float().to(device)\n",
    "        labels = torch.from_numpy(labels).to(device)\n",
    "        #print(\"trajs\")\n",
    "        #print(traj_i)\n",
    "        #print(traj_j)\n",
    "        \n",
    "        #zero out gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #forward + backward + optimize\n",
    "        outputs = reward_network.forward(traj_i, traj_j).unsqueeze(0)\n",
    "        #print(outputs)\n",
    "        #print(labels)\n",
    "        loss = loss_criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #print stats to see if learning\n",
    "        item_loss = loss.item()\n",
    "        cum_loss += item_loss\n",
    "        if epoch % 50 == 49:\n",
    "            #with torch.no_grad():\n",
    "            #    print(torch.cat([reward_network.cum_return(torch.from_numpy(np.array(traj)).float()) for traj in trajectories]))\n",
    "            print(epoch, cum_loss / 50)\n",
    "            cum_loss = 0.0\n",
    "    print(\"finished training\")\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a reward network and optimize it using the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doesn't work on my laptop, CUDA out of memory!!!\n",
    "reward = Net()\n",
    "#reward.to(device)\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(reward.parameters(), lr = 0.00001, weight_decay=0.001)\n",
    "learn_reward(reward, optimizer, train_demos, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out learned return for all demos. should be roughly increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    print(torch.cat([reward.cum_return(torch.from_numpy(np.array(traj)).float().to(device)) for traj in demonstrations]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at predicted reward over last demo. It's all +1 since demos are monotonically increasing. Maybe need to truncate demos to fixed length?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for last demo\n",
    "\n",
    "cnt = 0\n",
    "with torch.no_grad():\n",
    "    for d in demonstrations:\n",
    "        rewards = []\n",
    "        print(cnt)\n",
    "        for s in d:\n",
    "            r = reward.cum_return(torch.from_numpy(np.array([s])).float().to(device)).item()\n",
    "            rewards.append(r)\n",
    "        plt.figure(cnt)\n",
    "        plt.plot(rewards)\n",
    "        plt.xlabel(\"time\")\n",
    "        plt.ylabel(\"reward\")\n",
    "        plt.title(\"true return = {}\".format(learning_returns[cnt]))\n",
    "        cnt += 1\n",
    "#plt.savefig(\"learned_mcar_return.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying shorter snippets of the demos, should use a sliding window over all demos to get lots of training data, but just  trying the last H frames for now, where H is length of first (the shortest) demo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = len(train_demos[0])\n",
    "print(H)\n",
    "demos_fh = [d[len(d)-H:-1] for d in train_demos]\n",
    "print(len(demos_fh))\n",
    "reward_fh = Net()\n",
    "reward_fh.to(device)\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(reward_fh.parameters(),  lr = 0.0001)\n",
    "learn_reward(reward_fh, optimizer, demos_fh, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what predicted returns look like compared to actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pred_returns = [reward_fh.cum_return(torch.from_numpy(np.array(traj)).float().to(device)).item() for traj in train_demos]\n",
    "for i, p in enumerate(pred_returns):\n",
    "    print(i,p,train_returns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the actual time series of rewards predicted by nnet for each trajectory.\n",
    "#They are monotonically increasing, so that's good!\n",
    "for d in demos_fh:\n",
    "    print(len(d))\n",
    "\n",
    "cnt = 0\n",
    "with torch.no_grad():\n",
    "    for d in train_demos:\n",
    "        rewards = []\n",
    "        print(cnt)\n",
    "        for s in d:\n",
    "            r = reward_fh.cum_return(torch.from_numpy(np.array([s])).float().to(device)).item()\n",
    "            rewards.append(r)\n",
    "        plt.figure(cnt)\n",
    "        plt.plot(rewards)\n",
    "        plt.xlabel(\"time\")\n",
    "        plt.ylabel(\"reward\")\n",
    "        plt.title(\"true return = {}\".format(train_returns[cnt]))\n",
    "        cnt += 1\n",
    "#plt.savefig(\"learned_mcar_return.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pred_returns = [reward_fh.cum_return(torch.from_numpy(np.array(traj)).float().to(device)).item() for traj in valid_demos]\n",
    "for i, p in enumerate(pred_returns):\n",
    "    print(i,p,valid_returns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(reward_fh.state_dict(), \"./breakout_1_15_lastXreward_sorted.params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test reloading policy and see why giving zero reward when I run it inside of PPO.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_net = Net()\n",
    "test_net.to(device)\n",
    "test_net.load_state_dict(torch.load(\"./breakout_1_15_lastXreward_sorted.params\"))\n",
    "obs = demonstrations[10][400]\n",
    "plt.imshow(obs[0,:,:,3])\n",
    "with torch.no_grad():\n",
    "    test_r = test_net.cum_return(torch.from_numpy(np.array([obs])).float().to(device)).cpu().numpy().transpose()[0]\n",
    "print(test_r)\n",
    "\n",
    "import pickle\n",
    "filename = 'rand_obs.pkl'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(obs,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open(filename,'rb')\n",
    "new_obs = pickle.load(infile)\n",
    "infile.close()\n",
    "(obs == new_obs).all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
